{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1ce45515",
   "metadata": {},
   "source": [
    "Samuel Bitton : 2246844\n",
    "\n",
    "Ricardo Caster : 342688405\n",
    "\n",
    "https://github.com/RicardoCaster/lemidat_mehona.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "532f73bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6c52b0eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>property_type</th>\n",
       "      <th>neighborhood</th>\n",
       "      <th>address</th>\n",
       "      <th>room_num</th>\n",
       "      <th>floor</th>\n",
       "      <th>area</th>\n",
       "      <th>garden_area</th>\n",
       "      <th>days_to_enter</th>\n",
       "      <th>num_of_payments</th>\n",
       "      <th>monthly_arnona</th>\n",
       "      <th>...</th>\n",
       "      <th>ac</th>\n",
       "      <th>handicap</th>\n",
       "      <th>has_bars</th>\n",
       "      <th>has_safe_room</th>\n",
       "      <th>has_balcony</th>\n",
       "      <th>is_furnished</th>\n",
       "      <th>is_renovated</th>\n",
       "      <th>num_of_images</th>\n",
       "      <th>distance_from_center</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>דירה</td>\n",
       "      <td>הצפון הישן החלק המרכזי</td>\n",
       "      <td>מהר\"ל 25</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2</td>\n",
       "      <td>71</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>467.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1005.0</td>\n",
       "      <td>10150.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>דירה</td>\n",
       "      <td>הצפון הישן החלק המרכזי</td>\n",
       "      <td>ארלוזורוב 35</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>70</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>240.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>253.0</td>\n",
       "      <td>6600.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>דירה</td>\n",
       "      <td>הצפון הישן החלק המרכזי</td>\n",
       "      <td>וורמיזה 5</td>\n",
       "      <td>2.5</td>\n",
       "      <td>1</td>\n",
       "      <td>65</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12.0</td>\n",
       "      <td>400.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>8.0</td>\n",
       "      <td>740.0</td>\n",
       "      <td>9000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>דירה</td>\n",
       "      <td>הצפון הישן החלק המרכזי</td>\n",
       "      <td>עמנואל הרומי 30</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3</td>\n",
       "      <td>40</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1206.0</td>\n",
       "      <td>5800.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>דירה</td>\n",
       "      <td>הצפון הישן החלק המרכזי</td>\n",
       "      <td>ארלוזורוב 50</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>70</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>250.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5.0</td>\n",
       "      <td>255.0</td>\n",
       "      <td>7700.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  property_type            neighborhood          address  room_num floor  \\\n",
       "0          דירה  הצפון הישן החלק המרכזי         מהר\"ל 25       3.0     2   \n",
       "1          דירה  הצפון הישן החלק המרכזי     ארלוזורוב 35       3.0     1   \n",
       "2          דירה  הצפון הישן החלק המרכזי        וורמיזה 5       2.5     1   \n",
       "3          דירה  הצפון הישן החלק המרכזי  עמנואל הרומי 30       2.0     3   \n",
       "4          דירה  הצפון הישן החלק המרכזי     ארלוזורוב 50       3.0     1   \n",
       "\n",
       "   area  garden_area  days_to_enter  num_of_payments  monthly_arnona  ...  ac  \\\n",
       "0    71          NaN            0.0             12.0           467.0  ...   1   \n",
       "1    70          NaN            0.0             12.0           240.0  ...   1   \n",
       "2    65          NaN            NaN             12.0           400.0  ...   1   \n",
       "3    40          NaN            0.0             12.0           100.0  ...   0   \n",
       "4    70          NaN            0.0             11.0           250.0  ...   1   \n",
       "\n",
       "   handicap has_bars  has_safe_room  has_balcony  is_furnished  is_renovated  \\\n",
       "0       0.0        0              1            1             0             0   \n",
       "1       0.0        1              0            1             0             0   \n",
       "2       1.0        0              0            1             0             1   \n",
       "3       0.0        0              0            0             0             0   \n",
       "4       0.0        1              0            0             0             1   \n",
       "\n",
       "   num_of_images  distance_from_center    price  \n",
       "0            6.0                1005.0  10150.0  \n",
       "1            3.0                 253.0   6600.0  \n",
       "2            8.0                 740.0   9000.0  \n",
       "3            2.0                1206.0   5800.0  \n",
       "4            5.0                 255.0   7700.0  \n",
       "\n",
       "[5 rows x 26 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_excel('C:/Users/sam_b/Desktop/train.xlsx')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "83dccea9-5b9b-4e21-b35f-02cd0c4e0220",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data(df, mode=\"train\"):\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    \n",
    "### Clean and preprocess both TRAIN and TEST datasets automatically The function detects whether 'price' exists to decide how to treat the data (point 4 below).\n",
    "    \n",
    "    # --- 1. Keep only regular apartments ---\n",
    "    df = df[df['property_type'] == 'דירה']\n",
    "\n",
    "    # --- 2. Drop irrelevant columns ---\n",
    "    columns_to_drop = ['address', 'description', 'num_of_payments', 'num_of_images']\n",
    "    df = df.drop(columns=[col for col in columns_to_drop if col in df.columns], errors='ignore')\n",
    "\n",
    "    # --- 3. Convert important columns to numeric ---\n",
    "    numeric_cols = ['room_num', 'area', 'price', 'floor', 'total_floors',\n",
    "                    'monthly_arnona', 'building_tax', 'days_to_enter', 'distance_from_center']\n",
    "    for col in numeric_cols:\n",
    "        if col in df.columns:\n",
    "            df[col] = pd.to_numeric(df[col], errors='coerce')\n",
    "\n",
    "    # --- 4. Drop rows with unrealistic price only if we are in training set\n",
    "    if 'price' in df.columns:\n",
    "        df = df[df['price'].notna()]\n",
    "        df = df[(df['price'] >= 1000) & (df['price'] <= 50000)]\n",
    "\n",
    "    # --- 5. Remove unrealistic area values ---\n",
    "    df = df[df['area'] >= 10]\n",
    "\n",
    "    # --- 6. Remove rows without neighborhood ---\n",
    "    df = df[df['neighborhood'].notna()]\n",
    "\n",
    "    # --- 7. Impute room_num when equal to 0 using similar apartments by area ---\n",
    "    def impute_room_num(row, reference_df):\n",
    "        if row['room_num'] == 0:\n",
    "            similar = reference_df[\n",
    "                (reference_df['area'] >= row['area'] - 5) &\n",
    "                (reference_df['area'] <= row['area'] + 5) &\n",
    "                (reference_df['room_num'] > 0)\n",
    "            ]\n",
    "            if not similar.empty:\n",
    "                return round(similar['room_num'].median(), 1)\n",
    "            else:\n",
    "                return round(reference_df['room_num'].median(), 1)\n",
    "        return row['room_num']\n",
    "\n",
    "    if 'room_num' in df.columns and 'area' in df.columns:\n",
    "        reference_df = df[df['room_num'] > 0]\n",
    "        df['room_num'] = df.apply(lambda row: impute_room_num(row, reference_df), axis=1)\n",
    "\n",
    "    # --- 8. Fix total_floors if it's less than floor ---\n",
    "    if 'floor' in df.columns and 'total_floors' in df.columns:\n",
    "        df.loc[(df['floor'] > df['total_floors']) & df['total_floors'].notna(), 'total_floors'] = df['floor']\n",
    "\n",
    "    # --- 9. Fill missing total_floors using floor or median ---\n",
    "    if 'total_floors' in df.columns:\n",
    "        median_total = df[df['total_floors'] > 0]['total_floors'].median()\n",
    "\n",
    "        def fix_missing_total_floors(row):\n",
    "            if pd.isna(row['total_floors']):\n",
    "                if not pd.isna(row['floor']):\n",
    "                    return max(row['floor'], median_total)\n",
    "                else:\n",
    "                    return median_total\n",
    "            return row['total_floors']\n",
    "\n",
    "        df['total_floors'] = df.apply(fix_missing_total_floors, axis=1)\n",
    "\n",
    "    # --- 10. Fill missing values in each column with reasonable defaults ---\n",
    "    if 'floor' in df.columns:\n",
    "        df['floor'] = df['floor'].fillna(df['floor'].median())\n",
    "    if 'days_to_enter' in df.columns:\n",
    "        df['days_to_enter'] = df['days_to_enter'].fillna(df['days_to_enter'].median())\n",
    "    if 'distance_from_center' in df.columns:\n",
    "        df['distance_from_center'] = df['distance_from_center'].fillna(df['distance_from_center'].median())\n",
    "    if 'monthly_arnona' in df.columns:\n",
    "        df['monthly_arnona'] = df['monthly_arnona'].fillna(df['monthly_arnona'].mean())\n",
    "    if 'building_tax' in df.columns:\n",
    "        df['building_tax'] = df['building_tax'].fillna(df['building_tax'].mean())\n",
    "    if 'garden_area' in df.columns:\n",
    "        df['garden_area'] = df['garden_area'].fillna(0)\n",
    "\n",
    "    # --- 11. Encode 'neighborhood' with one-hot encoding ---\n",
    "    if 'neighborhood' in df.columns:\n",
    "        df = pd.get_dummies(df, columns=['neighborhood'], drop_first=True)\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "495e488f",
   "metadata": {},
   "source": [
    "## Data Cleaning Explanation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21942af7",
   "metadata": {},
   "source": [
    "1. Removed irrelevant columns\n",
    "We dropped the columns: address, description, num_of_payments, and num_of_images.\n",
    "\n",
    "address was removed because we already used neighborhood, which provides enough location information.\n",
    "\n",
    "description contains free text that we did not analyze, so it adds noise but no value.\n",
    "\n",
    "num_of_payments and num_of_images are not meaningful features for predicting rent price — they describe marketing or listing behavior, not the property itself.\n",
    "\n",
    "2. Filtered for regular apartments\n",
    "We kept only rows where property_type is equal to \"דירה\" (apartment).\n",
    "\n",
    "This was done to focus only on standard residential apartments, and not include commercial units, houses, or other real estate types that follow different pricing logic.\n",
    "\n",
    "3. Dropped rows with missing critical values\n",
    "We removed rows where price or neighborhood was missing.\n",
    "\n",
    "These are essential features: price is our target variable, and neighborhood is one of the most influential predictors.\n",
    "\n",
    "Without them, the row cannot be used for training or prediction.\n",
    "\n",
    "\n",
    "4. Removed unrealistic values\n",
    "Rows where area < 10 square meters were deleted.\n",
    "\n",
    "Rows where price < 1000 or price > 50000 were also removed.\n",
    "\n",
    " These were considered outliers or errors that could distort the model’s learning.\n",
    "\n",
    "5. Fixed invalid number of rooms\n",
    "If room_num == 0, we replaced it using the median number of rooms for similar apartments with the same area (±5m²).\n",
    "\n",
    "A value of 0 rooms is unrealistic, so we used nearby data to infer a reasonable value without removing the row.\n",
    "\n",
    "6. Corrected inconsistent total floors\n",
    "If floor > total_floors, we set total_floors = floor.\n",
    "\n",
    "An apartment cannot be on the 5th floor of a 4-floor building, so we assumed a minimum total equal to its floor.\n",
    "\n",
    "If total_floors was missing:\n",
    "\n",
    "We used the maximum of floor or the median of total_floors to replace it.\n",
    "\n",
    "\n",
    "7. Filled missing values by column\n",
    "We filled missing values using different strategies depending on the column:\n",
    "\n",
    "-For floor, we used the median value. This avoids the influence of extreme values and keeps the data realistic.\n",
    "\n",
    "-For total_floors, if missing, we applied logic: if the apartment’s floor is known, we took the maximum between the current floor and the median of total_floors.\n",
    "\n",
    "-For days_to_enter, we used the median, since it's a neutral value that doesn’t suggest immediate or delayed availability.\n",
    "\n",
    "-For distance_from_center, we filled missing values with the median, to avoid bias from outliers.\n",
    "\n",
    "-For monthly_arnona and building_tax, we used the mean because those are regular numeric costs that vary smoothly.\n",
    "For garden_area, we used 0 assuming that if no value was recorded, the apartment most likely has no garden.\n",
    "\n",
    "\n",
    "8. Encoded categorical variable\n",
    "We used one-hot encoding on the column neighborhood with drop_first=True.\n",
    "\n",
    "This allows the model to use neighborhoods as numeric input while avoiding multicollinearity.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5a890cb2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>property_type</th>\n",
       "      <th>room_num</th>\n",
       "      <th>floor</th>\n",
       "      <th>area</th>\n",
       "      <th>garden_area</th>\n",
       "      <th>days_to_enter</th>\n",
       "      <th>monthly_arnona</th>\n",
       "      <th>building_tax</th>\n",
       "      <th>total_floors</th>\n",
       "      <th>has_parking</th>\n",
       "      <th>...</th>\n",
       "      <th>neighborhood_קרית שלום</th>\n",
       "      <th>neighborhood_רביבים</th>\n",
       "      <th>neighborhood_רמת אביב ג</th>\n",
       "      <th>neighborhood_רמת אביב החדשה</th>\n",
       "      <th>neighborhood_שבזי</th>\n",
       "      <th>neighborhood_שיכון בבלי</th>\n",
       "      <th>neighborhood_שפירא</th>\n",
       "      <th>neighborhood_תל ברוך צפון</th>\n",
       "      <th>neighborhood_תל חיים</th>\n",
       "      <th>neighborhood_תל כביר</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>דירה</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>71</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>467.0</td>\n",
       "      <td>614.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>דירה</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>70</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>240.0</td>\n",
       "      <td>190.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>דירה</td>\n",
       "      <td>2.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>65</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>400.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>דירה</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>40</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>דירה</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>70</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>250.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 67 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  property_type  room_num  floor  area  garden_area  days_to_enter  \\\n",
       "0          דירה       3.0    2.0    71          0.0            0.0   \n",
       "1          דירה       3.0    1.0    70          0.0            0.0   \n",
       "2          דירה       2.5    1.0    65          0.0            0.0   \n",
       "3          דירה       2.0    3.0    40          0.0            0.0   \n",
       "4          דירה       3.0    1.0    70          0.0            0.0   \n",
       "\n",
       "   monthly_arnona  building_tax  total_floors  has_parking  ...  \\\n",
       "0           467.0         614.0           4.0            1  ...   \n",
       "1           240.0         190.0           4.0            0  ...   \n",
       "2           400.0         150.0           4.0            1  ...   \n",
       "3           100.0         100.0           3.0            0  ...   \n",
       "4           250.0          50.0           4.0            0  ...   \n",
       "\n",
       "   neighborhood_קרית שלום  neighborhood_רביבים  neighborhood_רמת אביב ג  \\\n",
       "0                       0                    0                        0   \n",
       "1                       0                    0                        0   \n",
       "2                       0                    0                        0   \n",
       "3                       0                    0                        0   \n",
       "4                       0                    0                        0   \n",
       "\n",
       "   neighborhood_רמת אביב החדשה  neighborhood_שבזי  neighborhood_שיכון בבלי  \\\n",
       "0                            0                  0                        0   \n",
       "1                            0                  0                        0   \n",
       "2                            0                  0                        0   \n",
       "3                            0                  0                        0   \n",
       "4                            0                  0                        0   \n",
       "\n",
       "   neighborhood_שפירא  neighborhood_תל ברוך צפון  neighborhood_תל חיים  \\\n",
       "0                   0                          0                     0   \n",
       "1                   0                          0                     0   \n",
       "2                   0                          0                     0   \n",
       "3                   0                          0                     0   \n",
       "4                   0                          0                     0   \n",
       "\n",
       "   neighborhood_תל כביר  \n",
       "0                     0  \n",
       "1                     0  \n",
       "2                     0  \n",
       "3                     0  \n",
       "4                     0  \n",
       "\n",
       "[5 rows x 67 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_excel('C:/Users/sam_b/Desktop/train.xlsx')\n",
    "df = prepare_data(df)\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "dd309b57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "property_type                               0\n",
       "neighborhood_נוה שאנן                       0\n",
       "neighborhood_יד אליהו                       0\n",
       "neighborhood_יפו ד                          0\n",
       "neighborhood_כפיר                           0\n",
       "                                           ..\n",
       "neighborhood_הצפון החדש סביבת ככר המדינה    0\n",
       "neighborhood_הצפון הישן החלק הדרום מזרחי    0\n",
       "neighborhood_הצפון הישן החלק הדרום מערבי    0\n",
       "neighborhood_הצפון הישן החלק המרכזי         0\n",
       "neighborhood_תל כביר                        0\n",
       "Length: 67, dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum().sort_values(ascending=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc8a5123",
   "metadata": {},
   "source": [
    "# elastic net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c6931bb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error (MAE): 1594.69\n",
      "ElasticNet RMSE: 2357.22\n",
      "R² Score: 0.59\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_absolute_error, r2_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "df = pd.read_excel('C:/Users/sam_b/Desktop/train.xlsx')\n",
    "# Clean and preprocess the data using the custom PrepareData function\n",
    "df = prepare_data(df)\n",
    "\n",
    "# Split features and target\n",
    "X = df.drop(columns=['price', 'property_type'])  # Drop the target and unused category\n",
    "y = df['price']\n",
    "\n",
    "# Scale the features using standardization\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Split the dataset into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize and train the ElasticNet model\n",
    "model = ElasticNet(alpha=1.0, l1_ratio=0.3, random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate model performance\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "rmse_elastic = mean_squared_error(y_test, y_pred, squared=False)\n",
    "\n",
    "# Print performance metrics\n",
    "print(f\"Mean Absolute Error (MAE): {mae:.2f}\")\n",
    "print(f\"ElasticNet RMSE: {rmse_elastic:.2f}\")\n",
    "print(f\"R² Score: {r2:.2f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4263968e",
   "metadata": {},
   "source": [
    "# 10 fold cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5a781702",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10-Fold Cross-Validated MAE: 1822.67\n",
      "10-Fold Cross-Validated RMSE: 3237.06\n",
      "10-Fold Cross-Validated R² Score: 0.46\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.model_selection import KFold, cross_val_score, cross_val_predict\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_absolute_error, r2_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_excel('C:/Users/sam_b/Desktop/train.xlsx')\n",
    "df = prepare_data(df)\n",
    "\n",
    "\n",
    "\n",
    "# Separate features and target\n",
    "X = df.drop(columns=['price', 'property_type'])\n",
    "y = df['price']\n",
    "\n",
    "# Standardize the features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Initialize the model\n",
    "model = ElasticNet(alpha=1.0, l1_ratio=0.3, random_state=42)\n",
    "\n",
    "# Define 10-fold cross-validation\n",
    "kf = KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "\n",
    "# Perform cross-validated predictions\n",
    "y_pred = cross_val_predict(model, X_scaled, y, cv=kf)\n",
    "\n",
    "# Evaluate performance across all folds\n",
    "mae = mean_absolute_error(y, y_pred)\n",
    "r2 = r2_score(y, y_pred)\n",
    "rmse = mean_squared_error(y, y_pred, squared=False)\n",
    "\n",
    "# Print metrics\n",
    "print(f\"10-Fold Cross-Validated MAE: {mae:.2f}\")\n",
    "print(f\"10-Fold Cross-Validated RMSE: {rmse:.2f}\")\n",
    "print(f\"10-Fold Cross-Validated R² Score: {r2:.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "961a673e",
   "metadata": {},
   "source": [
    "# top 5 features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7af49e6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "area                 780.763688\n",
       "room_num             602.682624\n",
       "is_furnished         431.831220\n",
       "building_tax         415.854050\n",
       "neighborhood_שבזי    372.280167\n",
       "dtype: float64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Identifier les 5 features avec l'influence la plus forte sur le prix (positif ou négatif)\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Recharger les données nettoyées\n",
    "df = pd.read_excel('C:/Users/sam_b/Desktop/train.xlsx')\n",
    "df = prepare_data(df)\n",
    "\n",
    "# Séparer X et y\n",
    "X = df.drop(columns=['price', 'property_type'])\n",
    "y = df['price']\n",
    "\n",
    "# Standardisation\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Entraîner ElasticNet\n",
    "model = ElasticNet(alpha=1.0, l1_ratio=0.3, random_state=42)\n",
    "model.fit(X_scaled, y)\n",
    "\n",
    "# Extraire les coefficients\n",
    "coef = pd.Series(model.coef_, index=X.columns)\n",
    "\n",
    "# Obtenir les 5 features les plus influentes (en valeur absolue)\n",
    "top_5_features = coef.reindex(coef.abs().sort_values(ascending=False).head(5).index)\n",
    "\n",
    "top_5_features\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75e88a43",
   "metadata": {},
   "source": [
    "# Trees"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "413335cb",
   "metadata": {},
   "source": [
    "#  DecisionTreeRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "eaf55f20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree MAE: 1882.15\n",
      "Random Forest RMSE: 2711.52\n",
      "Decision Tree R² Score: 0.46\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error, r2_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import pandas as pd\n",
    "\n",
    "# Load and prepare the data\n",
    "df = pd.read_excel('C:/Users/sam_b/Desktop/train.xlsx')\n",
    "df = prepare_data(df)\n",
    "# Split features and target\n",
    "X = df.drop(columns=['price', 'property_type'])  # Drop target and unused category\n",
    "y = df['price']\n",
    "\n",
    "# No need to scale features for tree-based models\n",
    "# Split the data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize and train the decision tree regressor\n",
    "model = DecisionTreeRegressor(random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate model performance\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "rmse_rf = mean_squared_error(y_test, y_pred, squared=False)\n",
    "\n",
    "# Print evaluation metrics\n",
    "print(f\"Decision Tree MAE: {mae:.2f}\")\n",
    "print(f\"Random Forest RMSE: {rmse_rf:.2f}\")\n",
    "print(f\"Decision Tree R² Score: {r2:.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06f9564b",
   "metadata": {},
   "source": [
    "# Random Forest Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4367750b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest MAE: 1301.06\n",
      "Random Forest RMSE: 1845.47\n",
      "Random Forest R² Score: 0.75\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error, r2_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import pandas as pd\n",
    "\n",
    "# Load and prepare the data\n",
    "df = pd.read_excel('C:/Users/sam_b/Desktop/train.xlsx')\n",
    "df = prepare_data(df)\n",
    "# Split features and target\n",
    "X = df.drop(columns=['price', 'property_type'])  # Drop target and unused category\n",
    "y = df['price']\n",
    "\n",
    "# No need to scale features for tree-based models\n",
    "# Split the data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize and train the Random Forest model\n",
    "model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate model performance\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "rmse_rf = mean_squared_error(y_test, y_pred, squared=False)\n",
    "\n",
    "# Print evaluation metrics\n",
    "print(f\"Random Forest MAE: {mae:.2f}\")\n",
    "print(f\"Random Forest RMSE: {rmse_rf:.2f}\")\n",
    "print(f\"Random Forest R² Score: {r2:.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a057033",
   "metadata": {},
   "source": [
    "# RandomizedSearchCV "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ee7f7d0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameters found: {'n_estimators': 300, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_depth': 30}\n",
      "MAE after Randomized Search: 1303.42\n",
      "RMSE after Randomized Search : 1829.03\n",
      "R² Score after Randomized Search: 0.75\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import RandomizedSearchCV, train_test_split\n",
    "from sklearn.metrics import mean_absolute_error, r2_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import pandas as pd\n",
    "\n",
    "# Load and prepare the data\n",
    "df = pd.read_excel('C:/Users/sam_b/Desktop/train.xlsx')\n",
    "df = prepare_data(df)\n",
    "\n",
    "# Separate features and target\n",
    "X = df.drop(columns=['price', 'property_type'])\n",
    "y = df['price']\n",
    "\n",
    "# Split into train/test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define hyperparameter space\n",
    "param_dist = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_depth': [None, 10, 20, 30],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4]\n",
    "}\n",
    "\n",
    "# Set up RandomizedSearchCV\n",
    "rf = RandomForestRegressor(random_state=42)\n",
    "random_search = RandomizedSearchCV(\n",
    "    estimator=rf,\n",
    "    param_distributions=param_dist,\n",
    "    n_iter=10,\n",
    "    cv=5,\n",
    "    scoring='neg_mean_absolute_error',\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# Fit search\n",
    "random_search.fit(X_train, y_train)\n",
    "\n",
    "# Best model and evaluation\n",
    "best_model = random_search.best_estimator_\n",
    "y_pred = best_model.predict(X_test)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "rmse_rf = mean_squared_error(y_test, y_pred, squared=False)\n",
    "\n",
    "print(\"Best hyperparameters found:\", random_search.best_params_)\n",
    "print(f\"MAE after Randomized Search: {mae:.2f}\")\n",
    "print(f\"RMSE after Randomized Search : {rmse_rf:.2f}\")\n",
    "print(f\"R² Score after Randomized Search: {r2:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0eb07c55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(max_depth=30, n_estimators=300, random_state=42)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model = random_search.best_estimator_\n",
    "best_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9058195e",
   "metadata": {},
   "source": [
    "We used RandomizedSearchCV to optimize the hyperparameters of the Random Forest model.\n",
    "It is faster than Grid Search and sufficient for this case, as it samples a wide range of combinations without checking them all.\n",
    "This helps improve performance while saving computational time."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb99c96a",
   "metadata": {},
   "source": [
    "# 10-fold cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "334395dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10-Fold CV MAE: 1575.98\n",
      "10-Fold CV RMSE: 2752.36\n",
      "10-Fold CV R²: 0.61\n"
     ]
    }
   ],
   "source": [
    "\n",
    "kf = KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "y_pred_cv = cross_val_predict(best_model, X, y, cv=kf)\n",
    "mae_cv = mean_absolute_error(y, y_pred_cv)\n",
    "r2_cv = r2_score(y, y_pred_cv)\n",
    "rmse_cv = mean_squared_error(y, y_pred_cv, squared=False)\n",
    "\n",
    "print(f\"10-Fold CV MAE: {mae_cv:.2f}\")\n",
    "print(f\"10-Fold CV RMSE: {rmse_cv:.2f}\")\n",
    "print(f\"10-Fold CV R²: {r2_cv:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a0bab86",
   "metadata": {},
   "source": [
    "# top 5 features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e743d5bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "area                    0.592579\n",
      "building_tax            0.056902\n",
      "distance_from_center    0.043701\n",
      "monthly_arnona          0.038843\n",
      "total_floors            0.031799\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Extract and display the top 5 most important features from the trained Random Forest model\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Get feature importances from the trained model\n",
    "feature_importances = pd.Series(best_model.feature_importances_, index=X.columns)\n",
    "\n",
    "# Sort and get the top 5\n",
    "top_5_rf_features = feature_importances.sort_values(ascending=False).head(5)\n",
    "\n",
    "# Display\n",
    "print(top_5_rf_features)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6485713c",
   "metadata": {},
   "source": [
    "# Model Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "17b0486c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>MAE (Test Set)</th>\n",
       "      <th>RMSE (Test Set)</th>\n",
       "      <th>R² (Test Set)</th>\n",
       "      <th>MAE (10-Fold CV)</th>\n",
       "      <th>RMSE (10-Fold CV)</th>\n",
       "      <th>R² (10-Fold CV)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ElasticNet</td>\n",
       "      <td>1594.69</td>\n",
       "      <td>2357.22</td>\n",
       "      <td>0.59</td>\n",
       "      <td>1822.67</td>\n",
       "      <td>3237.06</td>\n",
       "      <td>0.46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>1301.06</td>\n",
       "      <td>1845.47</td>\n",
       "      <td>0.75</td>\n",
       "      <td>1575.98</td>\n",
       "      <td>2752.36</td>\n",
       "      <td>0.61</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Model  MAE (Test Set)  RMSE (Test Set)  R² (Test Set)  \\\n",
       "0     ElasticNet         1594.69          2357.22           0.59   \n",
       "1  Random Forest         1301.06          1845.47           0.75   \n",
       "\n",
       "   MAE (10-Fold CV)  RMSE (10-Fold CV)  R² (10-Fold CV)  \n",
       "0           1822.67            3237.06             0.46  \n",
       "1           1575.98            2752.36             0.61  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a comparison table between ElasticNet and RandomForest, now including RMSE as well\n",
    "model_comparison = pd.DataFrame({\n",
    "    'Model': ['ElasticNet', 'Random Forest'],\n",
    "    'MAE (Test Set)': [1594.69, 1301.06],\n",
    "    'RMSE (Test Set)': [2357.22, 1845.47],\n",
    "    'R² (Test Set)': [0.59, 0.75],\n",
    "    'MAE (10-Fold CV)': [1822.67, 1575.98],\n",
    "    'RMSE (10-Fold CV)': [3237.06, 2752.36],\n",
    "    'R² (10-Fold CV)': [0.46, 0.61]\n",
    "})\n",
    "\n",
    "\n",
    "model_comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "566c4d44",
   "metadata": {},
   "source": [
    "We compared two regression models: ElasticNet and Random Forest.\n",
    "Based on both test set performance and 10-fold cross-validation, the Random Forest model consistently outperformed ElasticNet.\n",
    "It achieved a lower Mean Absolute Error (MAE), a lower Root Mean Squared Error (RMSE), and a higher R² score, indicating better predictive accuracy and a stronger ability to explain the variance in apartment prices.\n",
    "ElasticNet, being a linear model, is simpler but less capable of capturing complex, nonlinear relationships in the data.\n",
    "In contrast, Random Forest, an ensemble of decision trees, adapts better to diverse patterns and interactions between features."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c5c7b74",
   "metadata": {},
   "source": [
    "# Comparison of important features between the models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "903e4994",
   "metadata": {},
   "source": [
    "There is some overlap between the most important features in both models.\n",
    "For example, both ElasticNet and Random Forest showed that area and building tax are very important for predicting apartment price.\n",
    "But each model also focused on different things:\n",
    "ElasticNet found features like number of rooms and furnished status important,\n",
    "while Random Forest gave more importance to features like distance from the center and monthly arnona.\n",
    "This is normal, because Random Forest can find more complex patterns that ElasticNet cannot."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79b3a190",
   "metadata": {},
   "source": [
    "# Explanation of the differences between the models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad7c00f5",
   "metadata": {},
   "source": [
    "The main difference between ElasticNet and Random Forest is how they learn from the data.\n",
    "ElasticNet is a linear model, which means it can only find straight-line relationships between features and the price.\n",
    "Random Forest is a non-linear model, so it can detect more complex patterns and interactions between features.\n",
    "This is why Random Forest had better performance in MAE, RMSE, and R².\n",
    "In simple cases, ElasticNet may work well, but in more complicated datasets like this one, Random Forest is usually more accurate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a8bcb4d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "4f2f439c-d0e2-4148-b473-81b3b38fbfab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# Save ElasticNet model\n",
    "with open(\"elasticnet_model.pkl\", \"wb\") as f:\n",
    "    pickle.dump(model, f)\n",
    "\n",
    "# Save Random Forest model\n",
    "with open(\"random_forest_model.pkl\", \"wb\") as f:\n",
    "    pickle.dump(best_model, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d1a9758c-c2b7-45b6-8b4a-fd51d42d22c1",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'X_test.xlsx'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_95868\\622032381.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m# === Load new data to predict on ===\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mdf_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_excel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"X_test.xlsx\"\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# Replace with actual test file otherwise the code will give an error\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[0mdf_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mprepare_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf_test\u001b[0m\u001b[1;33m)\u001b[0m         \u001b[1;31m# Use your existing cleaning function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\util\\_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    309\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    310\u001b[0m                 )\n\u001b[1;32m--> 311\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    312\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    313\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\io\\excel\\_base.py\u001b[0m in \u001b[0;36mread_excel\u001b[1;34m(io, sheet_name, header, names, index_col, usecols, squeeze, dtype, engine, converters, true_values, false_values, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, parse_dates, date_parser, thousands, decimal, comment, skipfooter, convert_float, mangle_dupe_cols, storage_options)\u001b[0m\n\u001b[0;32m    455\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mio\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mExcelFile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    456\u001b[0m         \u001b[0mshould_close\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 457\u001b[1;33m         \u001b[0mio\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mExcelFile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mio\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstorage_options\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstorage_options\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    458\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mio\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    459\u001b[0m         raise ValueError(\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\io\\excel\\_base.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, path_or_buffer, engine, storage_options)\u001b[0m\n\u001b[0;32m   1374\u001b[0m                 \u001b[0mext\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"xls\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1375\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1376\u001b[1;33m                 ext = inspect_excel_format(\n\u001b[0m\u001b[0;32m   1377\u001b[0m                     \u001b[0mcontent_or_path\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstorage_options\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstorage_options\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1378\u001b[0m                 )\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\io\\excel\\_base.py\u001b[0m in \u001b[0;36minspect_excel_format\u001b[1;34m(content_or_path, storage_options)\u001b[0m\n\u001b[0;32m   1248\u001b[0m         \u001b[0mcontent_or_path\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mBytesIO\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcontent_or_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1249\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1250\u001b[1;33m     with get_handle(\n\u001b[0m\u001b[0;32m   1251\u001b[0m         \u001b[0mcontent_or_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"rb\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstorage_options\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstorage_options\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mis_text\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1252\u001b[0m     ) as handle:\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\io\\common.py\u001b[0m in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    793\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    794\u001b[0m             \u001b[1;31m# Binary mode\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 795\u001b[1;33m             \u001b[0mhandle\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mioargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    796\u001b[0m         \u001b[0mhandles\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    797\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'X_test.xlsx'"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "\n",
    "# === Load new data to predict on ===\n",
    "df_test = pd.read_excel(\"X_test.xlsx\")  # Replace with actual test file otherwise the code will give an error\n",
    "df_test = prepare_data(df_test)         # Use your existing cleaning function\n",
    "\n",
    "# === Prepare features for prediction ===\n",
    "X_test = df_test.drop(columns=[\"price\"], errors=\"ignore\")  # If 'price' is not in test, no problem\n",
    "\n",
    "# === Load and predict with ElasticNet model ===\n",
    "with open(\"elasticnet_model.pkl\", \"rb\") as f:\n",
    "    elasticnet_loaded = pickle.load(f)\n",
    "\n",
    "y_pred_elasticnet = elasticnet_loaded.predict(X_test)\n",
    "print(\"ElasticNet Predictions:\")\n",
    "print(y_pred_elasticnet)\n",
    "\n",
    "# === Load and predict with Random Forest model ===\n",
    "with open(\"random_forest_model.pkl\", \"rb\") as f:\n",
    "    rf_loaded = pickle.load(f)\n",
    "\n",
    "y_pred_rf = rf_loaded.predict(X_test)\n",
    "print(\"Random Forest Predictions:\")\n",
    "print(y_pred_rf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c40a089-aba5-47d9-a9ab-1a835fdedce8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "465aa0a6-d9de-431e-bb6c-e432d34d9c54",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b09af21",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
